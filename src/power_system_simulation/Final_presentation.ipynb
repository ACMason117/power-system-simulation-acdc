{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation ACDC\n",
    "\n",
    "In this notebook we will walk through examples of this package. The following points are covered: \n",
    "- Find downstream vertices\n",
    "- Find alternative edges\n",
    "- Handle PGM input format\n",
    "- Raise errors if the data is incorrect. \n",
    "- Aggregate the power flow results in tables. \n",
    "- Show tables with data of powerflow calculations. \n",
    "- Calculate EV penetration levels. \n",
    "- Calculate optimal tap positions. \n",
    "- Do N-1 Calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "\n",
    "import pytest\n",
    "import graph_processing as tp  # Import power_system_simpulation.graphy_processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import power_flow_processing as pfp\n",
    "from graph_processing import (\n",
    "    EdgePairNotUniqueError,\n",
    "    GraphCycleError,\n",
    "    GraphNotFullyConnectedError,\n",
    "    GraphProcessor,\n",
    "    IDNotFoundError,\n",
    "    IDNotUniqueError,\n",
    "    InputLengthDoesNotMatchError,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Input dataset\n",
    "\n",
    "We create an input graph by using the following parameters: \n",
    "- `vertex_ids`\n",
    "- `edge_ids`\n",
    "- `edge_vertex_id_pairs`\n",
    "- `edge_enabled`\n",
    "- `source_vertex_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = [0, 2, 4, 6, 10]  # All unique vertex ids\n",
    "edge_ids = [1, 3, 5, 7, 8, 9]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [ # Which vertex ids are connected by an edge\n",
    "        (0, 2),  # edge 1\n",
    "        (0, 4),  # edge 3\n",
    "        (0, 6),  # edge 5\n",
    "        (2, 4),  # edge 7\n",
    "        (4, 6),  # edge 8\n",
    "        (2, 10),  # edge 9\n",
    "    ]\n",
    "edge_enabled = [True, True, True, False, False, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph will result in this visual representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      \\nvertex_0 (source) --edge_1(enabled)-- vertex_2 --edge_9(enabled)-- vertex_10\\n                 |                               |\\n                 |                           edge_7(disabled)\\n                 |                               |\\n                 -----------edge_3(enabled)-- vertex_4\\n                 |                               |\\n                 |                           edge_8(disabled)\\n                 |                               |\\n                 -----------edge_5(enabled)-- vertex_6\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''      \n",
    "vertex_0 (source) --edge_1(enabled)-- vertex_2 --edge_9(enabled)-- vertex_10\n",
    "                 |                               |\n",
    "                 |                           edge_7(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_3(enabled)-- vertex_4\n",
    "                 |                               |\n",
    "                 |                           edge_8(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_5(enabled)-- vertex_6\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Validation\n",
    "This graph is tested for the following conditions: \n",
    "1. `vertex_ids` and `edge_ids` should be unique.\n",
    "    - This function compares the length of all `vertex_ids` to the set of `vertex_ids` and gives an error if they are not the same. It uses the same approach for `edge_ids`.\n",
    "2. `edge_vertex_id_pairs` should have the same length as `edge_ids`.\n",
    "    - This function compares the length of the list of `edge_vertex_id_pairs` and `edge_ids`.\n",
    "3. `edge_vertex_id_pairs` should contain valid `vertex ids`.\n",
    "    - Using a loop all `edge_vertex_id_pairs` are checked to also be valid `edge_ids`.\n",
    "4. `edge_enabled` should have the same length as `edge_ids`.\n",
    "    - The length of the `edge_enabled` list is compared to length of the `edge_ids` list. \n",
    "5. `source_vertex_id` should be a valid `vertex_ids`.\n",
    "     - The `source_vertex_id` is checked to be part of `vertex_ids`.\n",
    "6. The graph should not contain cycles.\n",
    "    - An adjacency list is built and using depth first search cycles are detected. \n",
    "7. The graph should be fully connected.\n",
    "    - Using depth fist search the length of all the visited vertex and the length of `vertex_ids` is compared. \n",
    "8. Multiple edges should not connect the same two `vertex_ids`. \n",
    "    - A list of `edge_vertex_id_pairs` is compared to a list of the set of `edge_vertex_id_pairs`.\n",
    "\n",
    "This can be tested by calling the `tp.GraphProcessor` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = tp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "When for example not all `vertex_ids` are unique the following error will be raised: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(IDNotUniqueError) as excinfo:\n",
    "    GraphProcessor([1, 2, 3, 3, 5], [1, 2, 3], [(1, 2), (2, 3), (1, 5)], [True, True, True], 1)\n",
    "assert str(excinfo.value) == \"Vertex IDs are not unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = tp.GraphProcessor(\n",
    "        vertex_ids=vertex_ids,\n",
    "        edge_ids=edge_ids,\n",
    "        edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "        edge_enabled=edge_enabled,\n",
    "        source_vertex_id=source_vertex_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Find downstream vertices\n",
    "\n",
    " Given an `edge_id`, return all the vertices which are in the downstream of the edge, with respect to the source vertex. Including the downstream vertex of the edge itself!\n",
    " Only the `edge_enabled` are taken into account. \n",
    " The function returns a list of all downstream `vertex_ids`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "vertex_ids = [0, 2, 4]  # All unique vertex ids\n",
    "edge_ids = [1, 3]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [(0, 2), (2, 4)]  # Egde 1 and egde 3\n",
    "edge_enabled = [True, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex\n",
    "\n",
    "test3 = tp.GraphProcessor(\n",
    "        vertex_ids=vertex_ids,\n",
    "        edge_ids=edge_ids,\n",
    "        edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "        edge_enabled=edge_enabled,\n",
    "        source_vertex_id=source_vertex_id,\n",
    "    )\n",
    "\n",
    "downstream_vertices = test3.find_downstream_vertices(1)\n",
    "print(downstream_vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Find alternative edges \n",
    "Given an enabled edge the following analysis is done: \n",
    "- If this edge is going to be disabled. \n",
    "- Which (currently disabled) edge can be enabled to ensure that the graph is again fully connected and acyclic?\n",
    "- Return a list of all alternative edges.\n",
    "\n",
    "Our example graph would return the following results:   \n",
    "        Call find_alternative_edges with disabled_edge_id=1 will return [7]   \n",
    "        Call find_alternative_edges with disabled_edge_id=3 will return [7, 8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=5 will return [8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=9 will return []   \n",
    "\n",
    "This function can be used by using the `find_alternative_edges` function and giving an `edge_ids` as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative edge when disabling edge 1 is: [7]\n",
      "Alternative edge when disabling edge 3 are: [7, 8]\n",
      "Alternative edge when disabling edge 5 are: [8]\n",
      "Alternative edge when disabling edge 9 are: []\n"
     ]
    }
   ],
   "source": [
    "alternative_edges = test2.find_alternative_edges(1)\n",
    "print(\"Alternative edge when disabling edge 1 is:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(3)\n",
    "print(\"Alternative edge when disabling edge 3 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(5)\n",
    "print(\"Alternative edge when disabling edge 5 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(9)\n",
    "print(\"Alternative edge when disabling edge 9 are:\", alternative_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Power Grid Model (PGM) Input\n",
    "\n",
    "The following sections describe a power grid calculation module with the use of the `power-grid-model` library. Firstly, we must handle the following inputs:\n",
    "- A power grid in PGM format\n",
    "- A table containing active load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "- A table containing ractive load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "\n",
    "This data can be imported using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "\n",
    "grid_data = json_deserialize_from_file(\"input_network_data.json\")\n",
    "active_power_profile = pd.read_parquet(\"active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"reactive_power_profile.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `grid_data` consists of several different tables containing information about different elements of the grid, like lines, nodes, sources and load information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  from_node  to_node  from_status  to_status    r1   x1       c1  tan1  \\\n",
      "0   5          1        2            1          1  0.25  0.2  0.00001   0.0   \n",
      "1   6          2        3            1          1  0.25  0.2  0.00001   0.0   \n",
      "2   7          3        4            1          1  0.25  0.2  0.00001   0.0   \n",
      "\n",
      "   r0  x0  c0  tan0     i_n  \n",
      "0 NaN NaN NaN   NaN  1000.0  \n",
      "1 NaN NaN NaN   NaN  1000.0  \n",
      "2 NaN NaN NaN   NaN  1000.0  \n",
      "   id  u_rated\n",
      "0   1  10500.0\n",
      "1   2  10500.0\n",
      "2   3  10500.0\n",
      "3   4  10500.0\n",
      "   id  node  status  u_ref  u_ref_angle           sk  rx_ratio  z01_ratio\n",
      "0  11     1       1    1.0          NaN  200000000.0       NaN        NaN\n",
      "   id  node  status  type  p_specified  q_specified\n",
      "0   8     2       1     0          0.0          0.0\n",
      "1   9     3       1     0          0.0          0.0\n",
      "2  10     4       1     0          0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(grid_data['line']))\n",
    "print(pd.DataFrame(grid_data['node']))\n",
    "print(pd.DataFrame(grid_data['source']))\n",
    "print(pd.DataFrame(grid_data['sym_load']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `active_power_profile` and `reactive_power_profile` contain the power profiles for different loads, so they tell how much power should be supplied to for example a household or factory (loads) at what time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load_ID                         8              9              10\n",
      "Timestamp                                                       \n",
      "2024-01-01 00:00:00   97627.007855  430378.732745  205526.752143\n",
      "2024-01-01 01:00:00   89766.365994 -152690.401322  291788.226133\n",
      "2024-01-01 02:00:00 -124825.577475  783546.001564  927325.521002\n",
      "2024-01-01 03:00:00 -233116.962348  583450.076165   57789.839506\n",
      "2024-01-01 04:00:00  136089.122188  851193.276585 -857927.883604\n",
      "2024-01-01 05:00:00 -825741.400597 -959563.205119  665239.691096\n",
      "2024-01-01 06:00:00  556313.501900  740024.296494  957236.684466\n",
      "2024-01-01 07:00:00  598317.128433  -77041.275494  561058.352573\n",
      "2024-01-01 08:00:00 -763451.148262  279842.042655 -713293.425182\n",
      "2024-01-01 09:00:00  889337.834099   43696.643500 -170676.120019\n",
      "Load_ID                         8              9              10\n",
      "Timestamp                                                       \n",
      "2024-01-01 00:00:00 -470888.775791  548467.378868  -87699.335567\n",
      "2024-01-01 01:00:00  136867.897737 -962420.399127  235270.994152\n",
      "2024-01-01 02:00:00  224191.445445  233867.993750  887496.157029\n",
      "2024-01-01 03:00:00  363640.598207 -280984.198852 -125936.092401\n",
      "2024-01-01 04:00:00  395262.391855 -879549.056741  333533.430891\n",
      "2024-01-01 05:00:00  341275.739236 -579234.877852 -742147.404690\n",
      "2024-01-01 06:00:00 -369143.298152 -272578.458115  140393.540836\n",
      "2024-01-01 07:00:00 -122796.973075  976747.676118 -795910.378504\n",
      "2024-01-01 08:00:00 -582246.487810 -677380.964230  306216.650931\n",
      "2024-01-01 09:00:00 -493416.794920  -67378.454287 -511148.815997\n"
     ]
    }
   ],
   "source": [
    "print(active_power_profile)\n",
    "print(reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Constructing PGM using input data\n",
    "\n",
    "Using the previously imported input data, a power grid model (PGM) can be constructed. Furthermore, validation is important in this step, and as such an error should be raised if the data is invalid. The PGM can be constructed by calling the class `pfp.PowerFlow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = pfp.PowerFlow(grid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PowerFlow` class contains an initialization function where the PGM is constructed, and the data is validated using the following line of code, which is already present in the actual function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.assert_valid_input_data(input_data=grid_data, symmetric=True, calculation_type=pfp.CalculationType.power_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 PGM Batch update dataset and power flow calculation\n",
    "\n",
    "The batch update dataset includes multiple power profiles (active and reactive power) for various nodes in the grid over a specified period. Instead of updating the grid model for each individual timestamp or node separately, the entire set of updates is applied at once, allowing us to perform the power flow calculation for the entire period.\n",
    "\n",
    "Within the `batch_powerflow` function, the power flow calculation is also performed. This is done using the Newton-Raphson method, which returns the `output_data` which contains the solution to the power flow calculation. Furthermore, the batch update dataset is also validated within the function.\n",
    "\n",
    "This entire functionality can easily be performed with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pgm.batch_powerflow(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Aggregating Power Flow Results\n",
    "\n",
    "Now all the data has been prepared and the state of the power grid after applying all batch updates has been computed, the power flow results will be aggregated in two tables:\n",
    "- A voltage table with each row representing a timestamp and containing the following columns:\n",
    "    - Timestamp (index column)\n",
    "    - Maximum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the maximum p.u. voltage\n",
    "    - Minimum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the minimum p.u. voltage\n",
    "\n",
    "- A loading table with each row representing a line and containing the following columns:\n",
    "    - Line ID (index column)\n",
    "    - Total energy loss of the line in kWh over the entire period\n",
    "    - Maximum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this maximum loading moment\n",
    "    - Minimum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this minimum loading moment\n",
    "\n",
    "These tables are constructed using two separate functions, which also gives the results for the given input data and power profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_Voltage</th>\n",
       "      <th>Max_Voltage_Node</th>\n",
       "      <th>Min_Voltage</th>\n",
       "      <th>Min_Voltage_Node</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01 00:00:00</th>\n",
       "      <td>1.004847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003450</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 01:00:00</th>\n",
       "      <td>1.012053</td>\n",
       "      <td>3</td>\n",
       "      <td>1.007998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 02:00:00</th>\n",
       "      <td>0.997474</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984365</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 03:00:00</th>\n",
       "      <td>1.006557</td>\n",
       "      <td>4</td>\n",
       "      <td>1.005190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 04:00:00</th>\n",
       "      <td>1.011007</td>\n",
       "      <td>4</td>\n",
       "      <td>1.005877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 05:00:00</th>\n",
       "      <td>1.020486</td>\n",
       "      <td>4</td>\n",
       "      <td>1.010570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 06:00:00</th>\n",
       "      <td>1.006342</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 07:00:00</th>\n",
       "      <td>1.004306</td>\n",
       "      <td>1</td>\n",
       "      <td>1.002822</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 08:00:00</th>\n",
       "      <td>1.020402</td>\n",
       "      <td>4</td>\n",
       "      <td>1.010501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-01 09:00:00</th>\n",
       "      <td>1.015742</td>\n",
       "      <td>4</td>\n",
       "      <td>1.010084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Max_Voltage  Max_Voltage_Node  Min_Voltage  \\\n",
       "Timestamp                                                         \n",
       "2024-01-01 00:00:00     1.004847                 1     1.003450   \n",
       "2024-01-01 01:00:00     1.012053                 3     1.007998   \n",
       "2024-01-01 02:00:00     0.997474                 1     0.984365   \n",
       "2024-01-01 03:00:00     1.006557                 4     1.005190   \n",
       "2024-01-01 04:00:00     1.011007                 4     1.005877   \n",
       "2024-01-01 05:00:00     1.020486                 4     1.010570   \n",
       "2024-01-01 06:00:00     1.006342                 1     0.998868   \n",
       "2024-01-01 07:00:00     1.004306                 1     1.002822   \n",
       "2024-01-01 08:00:00     1.020402                 4     1.010501   \n",
       "2024-01-01 09:00:00     1.015742                 4     1.010084   \n",
       "\n",
       "                     Min_Voltage_Node  \n",
       "Timestamp                              \n",
       "2024-01-01 00:00:00                 3  \n",
       "2024-01-01 01:00:00                 1  \n",
       "2024-01-01 02:00:00                 4  \n",
       "2024-01-01 03:00:00                 1  \n",
       "2024-01-01 04:00:00                 1  \n",
       "2024-01-01 05:00:00                 1  \n",
       "2024-01-01 06:00:00                 4  \n",
       "2024-01-01 07:00:00                 3  \n",
       "2024-01-01 08:00:00                 1  \n",
       "2024-01-01 09:00:00                 1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm.aggregate_voltage_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Loss</th>\n",
       "      <th>Max_Loading</th>\n",
       "      <th>Max_Loading_Timestamp</th>\n",
       "      <th>Min_Loading</th>\n",
       "      <th>Min_Loading_Timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63.294763</td>\n",
       "      <td>0.149830</td>\n",
       "      <td>2024-01-01 06:00:00</td>\n",
       "      <td>0.063798</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.775143</td>\n",
       "      <td>0.111039</td>\n",
       "      <td>2024-01-01 05:00:00</td>\n",
       "      <td>0.037184</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.872359</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Total_Loss  Max_Loading Max_Loading_Timestamp  Min_Loading  \\\n",
       "Line_ID                                                               \n",
       "5         63.294763     0.149830   2024-01-01 06:00:00     0.063798   \n",
       "6         36.775143     0.111039   2024-01-01 05:00:00     0.037184   \n",
       "7         14.872359     0.071700   2024-01-01 02:00:00     0.020380   \n",
       "\n",
       "        Min_Loading_Timestamp  \n",
       "Line_ID                        \n",
       "5         2024-01-01 03:00:00  \n",
       "6         2024-01-01 00:00:00  \n",
       "7         2024-01-01 01:00:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgm.aggregate_loading_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Using a LV grid with a MV/LV transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the package will present low voltage grid analytics functions. These analytics include EV penetration level and optimal tap position. Input data can be given as: \n",
    "- A LV grid in PGM input format.\n",
    "- LV feeder IDs list.\n",
    "- A (active and reactive) load profile.\n",
    "- A pool of EV charging profiles for the same time period as the time period of load profile.\n",
    "\n",
    "The data is validated to check for the following criteria: \n",
    "- The LV grid should be a valid PGM input data.\n",
    "- The LV grid has exactly one `transformer`, and one `source`.\n",
    "- All IDs in the LV Feeder IDs are valid line IDs.\n",
    "- All the lines in the LV Feeder IDs have the `from_node` the same as the `to_node` of the `transformer`.\n",
    "- The grid is fully connected in the initial state.\n",
    "- The grid has no cycles in the initial state.\n",
    "- The timestamps are matching between the active load profile, reactive load profile, and EV charging profile.\n",
    "- The IDs in active load profile and reactive load profile are matching.\n",
    "- The IDs in active load profile and reactive load profile are valid IDs of `sym_load`.\n",
    "- The number of EV charging profile is at least the same as the number of `sym_load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVs per feeder: 1\n",
      "Index([0, 1, 2, 3], dtype='object', name='EV Profile Sequence Number')\n",
      "Found line with from_node 1: to_node = 2\n",
      "Edge details: id = 16, r1 = 0.0003099357220775627, x1 = 0.0001406945054167883, ...\n",
      "{3, 5}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\20201933\\OneDrive - TU Eindhoven\\Year 4\\Power systems\\Laatste\\power-system-simulation-acdc\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\index_class_helper.pxi:100\u001b[0m, in \u001b[0;36mpandas._libs.index.Int32Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'node'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m ev_active_power_profile\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m assigned_profiles:\n\u001b[0;32m     68\u001b[0m                 \u001b[38;5;66;03m# Assign EV profile to active_power_profile at the corresponding node\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m                 active_power_profile\u001b[38;5;241m.\u001b[39mloc[\u001b[43mactive_power_profile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mev_profile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m idx\n\u001b[0;32m     70\u001b[0m                 assigned_profiles\u001b[38;5;241m.\u001b[39madd(idx)\n\u001b[0;32m     71\u001b[0m                 ev_assignment_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\20201933\\OneDrive - TU Eindhoven\\Year 4\\Power systems\\Laatste\\power-system-simulation-acdc\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\20201933\\OneDrive - TU Eindhoven\\Year 4\\Power systems\\Laatste\\power-system-simulation-acdc\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'node'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import graph_processing as tp  \n",
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "import power_flow_processing as pfp\n",
    "\n",
    "number_of_houses = 4\n",
    "number_of_feeders = 2\n",
    "penetration_level = 0.80\n",
    "total_evs = number_of_houses * penetration_level\n",
    "evs_per_feeder = math.floor(total_evs / number_of_feeders)\n",
    "print(f\"EVs per feeder: {evs_per_feeder}\")\n",
    "\n",
    "# Determine the file path relative to this script's location\n",
    "grid_data = json_deserialize_from_file(\"input_network_data_assign3.json\")\n",
    "active_power_profile = pd.read_parquet(\"active_power_profile.parquet\")\n",
    "ev_active_power_profile = pd.read_parquet(\"ev_active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"reactive_power_profile.parquet\")\n",
    "print(ev_active_power_profile.columns)\n",
    "    # Randomly select houses for EV assignment within each feeder\n",
    "    # These values should be given as an input from another file\n",
    "    # Within a LV feeder, randomly select houses which will have EVs\n",
    "    # For each selected house with EV, randomly select an EV charging profile to add to the sym_load of that house.\n",
    "    # After assignment of EV profiles, run a time-series power flow as in Assignment 2, return the two aggregation tables.\n",
    "edge_vertex_id_pairs = list(zip(grid_data[\"line\"][\"from_node\"], grid_data[\"line\"][\"to_node\"])) + list(\n",
    "            zip(grid_data[\"transformer\"][\"from_node\"], grid_data[\"transformer\"][\"to_node\"])\n",
    "        )\n",
    "edge_enabled = []\n",
    "for i in grid_data[\"line\"][\"id\"]:\n",
    "            index = np.where(grid_data[\"line\"][\"id\"] == i)\n",
    "            if grid_data[\"line\"][index][\"from_status\"] == 1 & grid_data[\"line\"][index][\"to_status\"] == 1:\n",
    "                edge_enabled = edge_enabled + [True]\n",
    "            else:\n",
    "                edge_enabled = edge_enabled + [False]\n",
    "if grid_data[\"transformer\"][0][\"from_status\"] == 1 & grid_data[\"transformer\"][0][\"to_status\"] == 1:\n",
    "            edge_enabled = edge_enabled + [True]\n",
    "else:\n",
    "            edge_enabled = edge_enabled + [False]\n",
    "source_vertex_id = grid_data[\"source\"][\"node\"][0]\n",
    "edge_ids = list(grid_data[\"line\"][\"id\"]) + list(grid_data[\"transformer\"][\"id\"])\n",
    "vertex_ids = grid_data[\"node\"][\"id\"]\n",
    "test4 = tp.GraphProcessor(\n",
    "        vertex_ids=vertex_ids,\n",
    "        edge_ids=edge_ids,\n",
    "        edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "        edge_enabled=edge_enabled,\n",
    "        source_vertex_id=source_vertex_id,\n",
    "    )\n",
    "transformer_to_node = grid_data[\"transformer\"][0][\"to_node\"]\n",
    "assigned_profiles = set()   # This keeps track of the assigned profiles\n",
    "for line in grid_data[\"line\"]:\n",
    "    if line[\"from_node\"] == transformer_to_node:\n",
    "        print(f\"Found line with from_node {transformer_to_node}: to_node = {line['to_node']}\")\n",
    "        print(f\"Edge details: id = {line['id']}, r1 = {line['r1']}, x1 = {line['x1']}, ...\")  # Find all feeders\n",
    "        downstream_vertices = test4.find_downstream_vertices(line['id'])\n",
    "        #print(downstream_vertices)\n",
    "        sym_load_nodes = set(grid_data['sym_load']['node'])\n",
    "        common_nodes = sym_load_nodes.intersection(downstream_vertices)\n",
    "        print(common_nodes) # all the nodes in a downstream vertex that have a sym load\n",
    "       '''\n",
    "        # ---- asigment of profiles\n",
    "        ev_assignment_counter = 0\n",
    "        for node in common_nodes:\n",
    "            if ev_assignment_counter >= evs_per_feeder:\n",
    "                break\n",
    "    for idx, row in ev_active_power_profile.iterrows():\n",
    "                if idx not in assigned_profiles:\n",
    "                    # Assign EV profile to active_power_profile at the corresponding node\n",
    "                    active_power_profile.loc[active_power_profile['node'] == node, 'ev_profile'] = idx\n",
    "                    assigned_profiles.add(idx)\n",
    "                    ev_assignment_counter += 1\n",
    "                    break\n",
    "                if ev_assignment_counter >= evs_per_feeder:\n",
    "                    break  # Stop further processing of lines once we've assigned enough EV profiles\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
