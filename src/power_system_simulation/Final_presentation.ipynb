{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation ACDC\n",
    "\n",
    "In this notebook we will walk through examples of this package. The following points are covered: \n",
    "- Find downstream vertices\n",
    "- Find alternative edges\n",
    "- Handle PGM input format\n",
    "- Raise errors if the data is incorrect. \n",
    "- Aggregate the power flow results in tables. \n",
    "- Show tables with data of powerflow calculations. \n",
    "- Calculate EV penetration levels. \n",
    "- Calculate optimal tap positions. \n",
    "- Do N-1 Calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "\n",
    "import pytest\n",
    "import graph_processing as tp  # Import power_system_simpulation.graphy_processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import power_flow_processing as pfp\n",
    "from graph_processing import (\n",
    "    EdgePairNotUniqueError,\n",
    "    GraphCycleError,\n",
    "    GraphNotFullyConnectedError,\n",
    "    GraphProcessor,\n",
    "    IDNotFoundError,\n",
    "    IDNotUniqueError,\n",
    "    InputLengthDoesNotMatchError,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Input dataset\n",
    "\n",
    "We create an input graph by using the following parameters: \n",
    "- `vertex_ids`\n",
    "- `edge_ids`\n",
    "- `edge_vertex_id_pairs`\n",
    "- `edge_enabled`\n",
    "- `source_vertex_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = [0, 2, 4, 6, 10]  # All unique vertex ids\n",
    "edge_ids = [1, 3, 5, 7, 8, 9]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [  # Which vertex ids are connected by an edge\n",
    "    (0, 2),  # edge 1\n",
    "    (0, 4),  # edge 3\n",
    "    (0, 6),  # edge 5\n",
    "    (2, 4),  # edge 7\n",
    "    (4, 6),  # edge 8\n",
    "    (2, 10),  # edge 9\n",
    "]\n",
    "edge_enabled = [True, True, True, False, False, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph will result in this visual representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"      \n",
    "vertex_0 (source) --edge_1(enabled)-- vertex_2 --edge_9(enabled)-- vertex_10\n",
    "                 |                               |\n",
    "                 |                           edge_7(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_3(enabled)-- vertex_4\n",
    "                 |                               |\n",
    "                 |                           edge_8(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_5(enabled)-- vertex_6\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Validation\n",
    "This graph is tested for the following conditions: \n",
    "1. `vertex_ids` and `edge_ids` should be unique.\n",
    "    - This function compares the length of all `vertex_ids` to the set of `vertex_ids` and gives an error if they are not the same. It uses the same approach for `edge_ids`.\n",
    "2. `edge_vertex_id_pairs` should have the same length as `edge_ids`.\n",
    "    - This function compares the length of the list of `edge_vertex_id_pairs` and `edge_ids`.\n",
    "3. `edge_vertex_id_pairs` should contain valid `vertex ids`.\n",
    "    - Using a loop all `edge_vertex_id_pairs` are checked to also be valid `edge_ids`.\n",
    "4. `edge_enabled` should have the same length as `edge_ids`.\n",
    "    - The length of the `edge_enabled` list is compared to length of the `edge_ids` list. \n",
    "5. `source_vertex_id` should be a valid `vertex_ids`.\n",
    "     - The `source_vertex_id` is checked to be part of `vertex_ids`.\n",
    "6. The graph should not contain cycles.\n",
    "    - An adjacency list is built and using depth first search cycles are detected. \n",
    "7. The graph should be fully connected.\n",
    "    - Using depth fist search the length of all the visited vertex and the length of `vertex_ids` is compared. \n",
    "8. Multiple edges should not connect the same two `vertex_ids`. \n",
    "    - A list of `edge_vertex_id_pairs` is compared to a list of the set of `edge_vertex_id_pairs`.\n",
    "\n",
    "This can be tested by calling the `tp.GraphProcessor` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = tp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "When for example not all `vertex_ids` are unique the following error will be raised: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(IDNotUniqueError) as excinfo:\n",
    "    GraphProcessor([1, 2, 3, 3, 5], [1, 2, 3], [(1, 2), (2, 3), (1, 5)], [True, True, True], 1)\n",
    "assert str(excinfo.value) == \"Vertex IDs are not unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Find downstream vertices\n",
    "\n",
    " Given an `edge_id`, return all the vertices which are in the downstream of the edge, with respect to the source vertex. Including the downstream vertex of the edge itself!\n",
    " Only the `edge_enabled` are taken into account. \n",
    " The function returns a list of all downstream `vertex_ids`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = [0, 2, 4]  # All unique vertex ids\n",
    "edge_ids = [1, 3]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [(0, 2), (2, 4)]  # Egde 1 and egde 3\n",
    "edge_enabled = [True, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex\n",
    "\n",
    "test3 = tp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    ")\n",
    "\n",
    "downstream_vertices = test3.find_downstream_vertices(1)\n",
    "print(downstream_vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Find alternative edges \n",
    "Given an enabled edge the following analysis is done: \n",
    "- If this edge is going to be disabled. \n",
    "- Which (currently disabled) edge can be enabled to ensure that the graph is again fully connected and acyclic?\n",
    "- Return a list of all alternative edges.\n",
    "\n",
    "Our example graph would return the following results:   \n",
    "        Call find_alternative_edges with disabled_edge_id=1 will return [7]   \n",
    "        Call find_alternative_edges with disabled_edge_id=3 will return [7, 8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=5 will return [8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=9 will return []   \n",
    "\n",
    "This function can be used by using the `find_alternative_edges` function and giving an `edge_ids` as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_edges = test2.find_alternative_edges(1)\n",
    "print(\"Alternative edge when disabling edge 1 is:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(3)\n",
    "print(\"Alternative edge when disabling edge 3 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(5)\n",
    "print(\"Alternative edge when disabling edge 5 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(9)\n",
    "print(\"Alternative edge when disabling edge 9 are:\", alternative_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Power Grid Model (PGM) Input\n",
    "\n",
    "The following sections describe a power grid calculation module with the use of the `power-grid-model` library. Firstly, we must handle the following inputs:\n",
    "- A power grid in PGM format\n",
    "- A table containing active load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "- A table containing ractive load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "\n",
    "This data can be imported using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "\n",
    "grid_data = json_deserialize_from_file(\"input_network_data.json\")\n",
    "active_power_profile = pd.read_parquet(\"active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"reactive_power_profile.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `grid_data` consists of several different tables containing information about different elements of the grid, like lines, nodes, sources and load information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(grid_data[\"line\"]))\n",
    "print(pd.DataFrame(grid_data[\"node\"]))\n",
    "print(pd.DataFrame(grid_data[\"source\"]))\n",
    "print(pd.DataFrame(grid_data[\"sym_load\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `active_power_profile` and `reactive_power_profile` contain the power profiles for different loads, so they tell how much power should be supplied to for example a household or factory (loads) at what time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(active_power_profile)\n",
    "display(reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Constructing PGM using input data\n",
    "\n",
    "Using the previously imported input data, a power grid model (PGM) can be constructed. Furthermore, validation is important in this step, and as such an error should be raised if the data is invalid. The PGM can be constructed by calling the class `pfp.PowerFlow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = pfp.PowerFlow(grid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PowerFlow` class contains an initialization function where the PGM is constructed, and the data is validated using the following line of code, which is already present in the actual function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.assert_valid_input_data(input_data=grid_data, symmetric=True, calculation_type=pfp.CalculationType.power_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 PGM Batch update dataset and power flow calculation\n",
    "\n",
    "The batch update dataset includes multiple power profiles (active and reactive power) for various nodes in the grid over a specified period. Instead of updating the grid model for each individual timestamp or node separately, the entire set of updates is applied at once, allowing us to perform the power flow calculation for the entire period.\n",
    "\n",
    "Within the `batch_powerflow` function, the power flow calculation is also performed. This is done using the Newton-Raphson method, which returns the `output_data` which contains the solution to the power flow calculation. Furthermore, the batch update dataset is also validated within the function.\n",
    "\n",
    "This entire functionality can easily be performed with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pgm.batch_powerflow(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Aggregating Power Flow Results\n",
    "\n",
    "Now all the data has been prepared and the state of the power grid after applying all batch updates has been computed, the power flow results will be aggregated in two tables:\n",
    "- A voltage table with each row representing a timestamp and containing the following columns:\n",
    "    - Timestamp (index column)\n",
    "    - Maximum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the maximum p.u. voltage\n",
    "    - Minimum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the minimum p.u. voltage\n",
    "\n",
    "- A loading table with each row representing a line and containing the following columns:\n",
    "    - Line ID (index column)\n",
    "    - Total energy loss of the line in kWh over the entire period\n",
    "    - Maximum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this maximum loading moment\n",
    "    - Minimum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this minimum loading moment\n",
    "\n",
    "These tables are constructed using two separate functions, which also gives the results for the given input data and power profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm.aggregate_voltage_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm.aggregate_loading_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Using a LV grid with a MV/LV transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the package will present low voltage grid analytics functions. These analytics include EV penetration level and optimal tap position. Input data can be given as: \n",
    "- A LV grid in PGM input format.\n",
    "- LV feeder IDs list.\n",
    "- A (active and reactive) load profile.\n",
    "- A pool of EV charging profiles for the same time period as the time period of load profile.\n",
    "\n",
    "The data is validated to check for the following criteria: \n",
    "- The LV grid should be a valid PGM input data.\n",
    "- The LV grid has exactly one `transformer`, and one `source`.\n",
    "- All IDs in the LV Feeder IDs are valid line IDs.\n",
    "- All the lines in the LV Feeder IDs have the `from_node` the same as the `to_node` of the `transformer`.\n",
    "- The grid is fully connected in the initial state.\n",
    "- The grid has no cycles in the initial state.\n",
    "- The timestamps are matching between the active load profile, reactive load profile, and EV charging profile.\n",
    "- The IDs in active load profile and reactive load profile are matching.\n",
    "- The IDs in active load profile and reactive load profile are valid IDs of `sym_load`.\n",
    "- The number of EV charging profile is at least the same as the number of `sym_load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import graph_processing as tp\n",
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "import power_flow_processing as pfp\n",
    "import power_system_simulation as pss\n",
    "\n",
    "number_of_houses = 4\n",
    "number_of_feeders = 2\n",
    "penetration_level = 0.80\n",
    "# total_evs = number_of_houses * penetration_level\n",
    "# evs_per_feeder = math.floor(total_evs / number_of_feeders)\n",
    "# print(f\"EVs per feeder: {evs_per_feeder}\")\n",
    "\n",
    "# Determine the file path relative to this script's location\n",
    "grid_data = json_deserialize_from_file(\"input_network_data_assign3.json\")\n",
    "active_power_profile = pd.read_parquet(\"active_power_profile.parquet\")\n",
    "ev_active_power_profile = pd.read_parquet(\"ev_active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"reactive_power_profile.parquet\")\n",
    "\n",
    "EV_test = pss.PowerSim(grid_data=grid_data)\n",
    "\n",
    "# print(ev_active_power_profile.columns)\n",
    "\n",
    "\n",
    "# Randomly select houses for EV assignment within each feeder\n",
    "# These values should be given as an input from another file\n",
    "# Within a LV feeder, randomly select houses which will have EVs\n",
    "# For each selected house with EV, randomly select an EV charging profile to add to the sym_load of that house.\n",
    "# After assignment of EV profiles, run a time-series power flow as in Assignment 2, return the two aggregation tables.\n",
    "\n",
    "# edge_vertex_id_pairs = list(zip(grid_data[\"line\"][\"from_node\"], grid_data[\"line\"][\"to_node\"])) + list(\n",
    "#             zip(grid_data[\"transformer\"][\"from_node\"], grid_data[\"transformer\"][\"to_node\"])\n",
    "#         )\n",
    "# edge_enabled = []\n",
    "# for i in grid_data[\"line\"][\"id\"]:\n",
    "#             index = np.where(grid_data[\"line\"][\"id\"] == i)\n",
    "#             if grid_data[\"line\"][index][\"from_status\"] == 1 & grid_data[\"line\"][index][\"to_status\"] == 1:\n",
    "#                 edge_enabled = edge_enabled + [True]\n",
    "#             else:\n",
    "#                 edge_enabled = edge_enabled + [False]\n",
    "# if grid_data[\"transformer\"][0][\"from_status\"] == 1 & grid_data[\"transformer\"][0][\"to_status\"] == 1:\n",
    "#             edge_enabled = edge_enabled + [True]\n",
    "# else:\n",
    "#             edge_enabled = edge_enabled + [False]\n",
    "# source_vertex_id = grid_data[\"source\"][\"node\"][0]\n",
    "# edge_ids = list(grid_data[\"line\"][\"id\"]) + list(grid_data[\"transformer\"][\"id\"])\n",
    "# vertex_ids = grid_data[\"node\"][\"id\"]\n",
    "# test4 = tp.GraphProcessor(\n",
    "#         vertex_ids=vertex_ids,\n",
    "#         edge_ids=edge_ids,\n",
    "#         edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "#         edge_enabled=edge_enabled,\n",
    "#         source_vertex_id=source_vertex_id,\n",
    "#     )\n",
    "# transformer_to_node = grid_data[\"transformer\"][0][\"to_node\"]\n",
    "\n",
    "# # assigned_profiles = set()   # This keeps track of the assigned profiles\n",
    "\n",
    "# for line in grid_data[\"line\"]:\n",
    "#     if line[\"from_node\"] == transformer_to_node:\n",
    "#         print(f\"Found line with from_node {transformer_to_node}: to_node = {line['to_node']}\")\n",
    "#         print(f\"Edge details: id = {line['id']}, r1 = {line['r1']}, x1 = {line['x1']}, ...\")  # Find all feeders\n",
    "#         downstream_vertices = test4.find_downstream_vertices(line['id'])\n",
    "#         #print(downstream_vertices)\n",
    "#         sym_load_nodes = set(grid_data['sym_load']['node'])\n",
    "#         common_nodes = sym_load_nodes.intersection(downstream_vertices)\n",
    "#         print(common_nodes) # all the nodes in a downstream vertex that have a sym load\n",
    "#         '''\n",
    "#         # ---- asigment of profiles\n",
    "#         ev_assignment_counter = 0\n",
    "#         for node in common_nodes:\n",
    "#             if ev_assignment_counter >= evs_per_feeder:\n",
    "#                 break\n",
    "#     for idx, row in ev_active_power_profile.iterrows():\n",
    "#                 if idx not in assigned_profiles:\n",
    "#                     # Assign EV profile to active_power_profile at the corresponding node\n",
    "#                     active_power_profile.loc[active_power_profile['node'] == node, 'ev_profile'] = idx\n",
    "#                     assigned_profiles.add(idx)\n",
    "#                     ev_assignment_counter += 1\n",
    "#                     break\n",
    "#                 if ev_assignment_counter >= evs_per_feeder:\n",
    "#                     break  # Stop further processing of lines once we've assigned enough EV profiles\n",
    "#         '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
