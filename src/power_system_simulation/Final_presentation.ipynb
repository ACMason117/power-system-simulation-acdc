{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Presentation ACDC\n",
    "\n",
    "In this notebook we will walk through examples of this package. The following points are covered: \n",
    "- Find downstream vertices\n",
    "- Find alternative edges\n",
    "- Handle PGM input format\n",
    "- Raise errors if the data is incorrect. \n",
    "- Aggregate the power flow results in tables. \n",
    "- Show tables with data of powerflow calculations. \n",
    "- Calculate EV penetration levels. \n",
    "- Calculate optimal tap positions. \n",
    "- Do N-1 calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic imports\n",
    "import pytest\n",
    "import graph_processing as tp  # Import power_system_simpulation.graphy_processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import power_flow_processing as pfp\n",
    "from graph_processing import (\n",
    "    EdgePairNotUniqueError,\n",
    "    GraphCycleError,\n",
    "    GraphNotFullyConnectedError,\n",
    "    GraphProcessor,\n",
    "    IDNotFoundError,\n",
    "    IDNotUniqueError,\n",
    "    InputLengthDoesNotMatchError,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Input dataset\n",
    "\n",
    "We create an input graph by using the following parameters: \n",
    "- `vertex_ids`\n",
    "- `edge_ids`\n",
    "- `edge_vertex_id_pairs`\n",
    "- `edge_enabled`\n",
    "- `source_vertex_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = [0, 2, 4, 6, 10]  # All unique vertex ids\n",
    "edge_ids = [1, 3, 5, 7, 8, 9]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [ # Which vertex ids are connected by an edge\n",
    "        (0, 2),  # edge 1\n",
    "        (0, 4),  # edge 3\n",
    "        (0, 6),  # edge 5\n",
    "        (2, 4),  # edge 7\n",
    "        (4, 6),  # edge 8\n",
    "        (2, 10),  # edge 9\n",
    "    ]\n",
    "edge_enabled = [True, True, True, False, False, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph will result in this visual representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''      \n",
    "vertex_0 (source) --edge_1(enabled)-- vertex_2 --edge_9(enabled)-- vertex_10\n",
    "                 |                               |\n",
    "                 |                           edge_7(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_3(enabled)-- vertex_4\n",
    "                 |                               |\n",
    "                 |                           edge_8(disabled)\n",
    "                 |                               |\n",
    "                 -----------edge_5(enabled)-- vertex_6\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Validation\n",
    "This graph is tested for the following conditions: \n",
    "1. `vertex_ids` and `edge_ids` should be unique.\n",
    "    - This function compares the length of all `vertex_ids` to the set of `vertex_ids` and gives an error if they are not the same. It uses the same approach for `edge_ids`.\n",
    "2. `edge_vertex_id_pairs` should have the same length as `edge_ids`.\n",
    "    - This function compares the length of the list of `edge_vertex_id_pairs` and `edge_ids`.\n",
    "3. `edge_vertex_id_pairs` should contain valid `vertex ids`.\n",
    "    - Using a loop all `edge_vertex_id_pairs` are checked to also be valid `edge_ids`.\n",
    "4. `edge_enabled` should have the same length as `edge_ids`.\n",
    "    - The length of the `edge_enabled` list is compared to length of the `edge_ids` list. \n",
    "5. `source_vertex_id` should be a valid `vertex_ids`.\n",
    "     - The `source_vertex_id` is checked to be part of `vertex_ids`.\n",
    "6. The graph should not contain cycles.\n",
    "    - An adjacency list is built and using depth first search cycles are detected. \n",
    "7. The graph should be fully connected.\n",
    "    - Using depth first search the length of all the visited vertex and the length of `vertex_ids` is compared. \n",
    "8. Multiple edges should not connect the same two `vertex_ids`. \n",
    "    - A list of `edge_vertex_id_pairs` is compared to a list of the set of `edge_vertex_id_pairs`.\n",
    "\n",
    "This can be tested by calling the `tp.GraphProcessor` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = tp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "When for example not all `vertex_ids` are unique the following error will be raised: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(IDNotUniqueError) as excinfo:\n",
    "    GraphProcessor([1, 2, 3, 3, 5], [1, 2, 3], [(1, 2), (2, 3), (1, 5)], [True, True, True], 1)\n",
    "assert str(excinfo.value) == \"Vertex IDs are not unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tp.GraphProcessor(\n",
    "        vertex_ids=vertex_ids,\n",
    "        edge_ids=edge_ids,\n",
    "        edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "        edge_enabled=edge_enabled,\n",
    "        source_vertex_id=source_vertex_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Find downstream vertices\n",
    "\n",
    " Given an `edge_id`, return all the vertices which are in the downstream of the edge, with respect to the source vertex. Including the downstream vertex of the edge itself!\n",
    " Only the `edge_enabled` are taken into account. \n",
    " The function returns a list of all downstream `vertex_ids`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = [0, 2, 4]  # All unique vertex ids\n",
    "edge_ids = [1, 3]  # All unique edge ids\n",
    "edge_vertex_id_pairs = [(0, 2), (2, 4)]  # Egde 1 and egde 3\n",
    "edge_enabled = [True, True]  # Whether each edge is enabled or disabled\n",
    "source_vertex_id = 0  # ID of the source vertex\n",
    "\n",
    "test3 = tp.GraphProcessor(\n",
    "        vertex_ids=vertex_ids,\n",
    "        edge_ids=edge_ids,\n",
    "        edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "        edge_enabled=edge_enabled,\n",
    "        source_vertex_id=source_vertex_id,\n",
    "    )\n",
    "\n",
    "downstream_vertices = test3.find_downstream_vertices(1)\n",
    "print(downstream_vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Find alternative edges \n",
    "Given an enabled edge the following analysis is done: \n",
    "- If this edge is going to be disabled. \n",
    "- Which (currently disabled) edge can be enabled to ensure that the graph is again fully connected and acyclic?\n",
    "- Return a list of all alternative edges.\n",
    "\n",
    "Our example graph would return the following results:   \n",
    "        Call find_alternative_edges with disabled_edge_id=1 will return [7]   \n",
    "        Call find_alternative_edges with disabled_edge_id=3 will return [7, 8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=5 will return [8]   \n",
    "        Call find_alternative_edges with disabled_edge_id=9 will return []   \n",
    "\n",
    "This function can be used by using the `find_alternative_edges` function and giving an `edge_ids` as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_edges = test2.find_alternative_edges(1)\n",
    "print(\"Alternative edge when disabling edge 1 is:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(3)\n",
    "print(\"Alternative edge when disabling edge 3 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(5)\n",
    "print(\"Alternative edge when disabling edge 5 are:\", alternative_edges)\n",
    "\n",
    "alternative_edges = test2.find_alternative_edges(9)\n",
    "print(\"Alternative edge when disabling edge 9 are:\", alternative_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the alternative edge function work?\n",
    "\n",
    "1. The user specifies an edge which is going to be disabled\n",
    "2. The function validates whether the specified edge ID exists and if it is not already disabled\n",
    "3. The function iterates through all edges, checking if they are disabled or not\n",
    "4. Once a disabled edge is found, it is enabled\n",
    "5. For this edge, an adjacency list with enabled edges is built using another function\n",
    "6. This adjacency list is used as input to the Depth-First-Search (DFS) function which checks for connectivity and cycles\n",
    "7. If the DFS function returns an acyclic and fully connected network, the edge is added to the alternative edges list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Power Grid Model (PGM) Input\n",
    "\n",
    "The following sections describe a power grid calculation module with the use of the `power-grid-model` library. Firstly, we must handle the following inputs:\n",
    "- A power grid in PGM format\n",
    "- A table containing active load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "- A table containing ractive load profile of all the `sym_load` in the grid, with timestamps and load ids.\n",
    "\n",
    "This data can be imported using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "\n",
    "grid_data = json_deserialize_from_file(\"input_network_data.json\")\n",
    "active_power_profile = pd.read_parquet(\"active_power_profile.parquet\")\n",
    "reactive_power_profile = pd.read_parquet(\"reactive_power_profile.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `grid_data` consists of several different tables containing information about different elements of the grid, like lines, nodes, sources and load information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(grid_data['line']))\n",
    "print(pd.DataFrame(grid_data['node']))\n",
    "print(pd.DataFrame(grid_data['source']))\n",
    "print(pd.DataFrame(grid_data['sym_load']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `active_power_profile` and `reactive_power_profile` contain the power profiles for different loads, so they tell how much power should be supplied to for example a household or factory (loads) at what time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(active_power_profile)\n",
    "print(reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Constructing PGM using input data\n",
    "\n",
    "Using the previously imported input data, a power grid model (PGM) can be constructed. Furthermore, validation is important in this step, and as such an error should be raised if the data is invalid. The PGM can be constructed by calling the class `pfp.PowerFlow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = pfp.PowerFlow(grid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PowerFlow` class contains an initialization function where the PGM is constructed, and the data is validated using the following line of code, which is already present in the actual function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.assert_valid_input_data(input_data=grid_data, symmetric=True, calculation_type=pfp.CalculationType.power_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 PGM Batch update dataset and power flow calculation\n",
    "\n",
    "The batch update dataset includes multiple power profiles (active and reactive power) for various nodes in the grid over a specified period. Instead of updating the grid model for each individual timestamp or node separately, the entire set of updates is applied at once, allowing us to perform the power flow calculation for the entire period.\n",
    "\n",
    "Within the `batch_powerflow` function, the power flow calculation is also performed. This is done using the Newton-Raphson method, which returns the `output_data` which contains the solution to the power flow calculation. Furthermore, the batch update dataset is also validated within the function.\n",
    "\n",
    "This entire functionality can easily be performed with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pgm.batch_powerflow(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Aggregating Power Flow Results\n",
    "\n",
    "Now all the data has been prepared and the state of the power grid after applying all batch updates has been computed, the power flow results will be aggregated in two tables:\n",
    "- A voltage table with each row representing a timestamp and containing the following columns:\n",
    "    - Timestamp (index column)\n",
    "    - Maximum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the maximum p.u. voltage\n",
    "    - Minimum p.u. voltage of all the nodes for this timestamp\n",
    "    - The node ID with the minimum p.u. voltage\n",
    "\n",
    "- A loading table with each row representing a line and containing the following columns:\n",
    "    - Line ID (index column)\n",
    "    - Total energy loss of the line in kWh over the entire period\n",
    "    - Maximum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this maximum loading moment\n",
    "    - Minimum loading in p.u. of the line across the whole timeline\n",
    "    - Timestamp of this minimum loading moment\n",
    "\n",
    "These tables are constructed using two separate functions, which also gives the results for the given input data and power profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm.aggregate_voltage_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the voltage table constructed?\n",
    "1. Firstly, a batch update dataset is made using the provided power profiles, which returns the results of the power flow calculation\n",
    "2. An empty `DataFrame` is created for the voltage table\n",
    "3. The `Timestamp` column of the table is filled with the index values of the active power profile, which are identical to the reactive power profile\n",
    "4. The maximum and minimum voltages per timestamp are calculated from the `output_data[\"node\"]` DataFrame\n",
    "5. The node ID's corresponding to these extremes are determined using the `idxmax` and `idxmin` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm.aggregate_loading_table(active_power_profile, reactive_power_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the loading table constructed?\n",
    "1. Firstly, a batch update dataset is made using the provided power profiles, which returns the results of the power flow calculation\n",
    "2. The line data from the power flow results is selected and an empty DataFrame is created for the loading table\n",
    "3. The power data `p_from` and `p_to` is extracted, representing the power flow into and out of a line\n",
    "4. The power losses are calculated and converted to kWh by adding `p_to` and `p_from`\n",
    "5. The energy losses are calculated by using the `scipy` function `integrate.trapezoid()`, allowing trapezoidal integration\n",
    "6. The maximum and minimum loading is found using the `.max()` and `.min()` functionalities\n",
    "7. The maximum and minimum loading ID's are used to find the corresponding timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Using a LV grid with a MV/LV transformer\n",
    "This part of the package will present low voltage grid analytics functions. These analytics include EV penetration level and optimal tap position. Input data can be given as: \n",
    "- A LV grid in PGM input format.\n",
    "- LV feeder IDs list.\n",
    "- A (active and reactive) load profile.\n",
    "- A pool of EV charging profiles for the same time period as the time period of load profile.\n",
    "\n",
    "The data is validated to check for the following criteria: \n",
    "- The LV grid should be a valid PGM input data.\n",
    "- The LV grid has exactly one `transformer`, and one `source`.\n",
    "- All IDs in the LV Feeder IDs are valid line IDs.\n",
    "- All the lines in the LV Feeder IDs have the `from_node` the same as the `to_node` of the `transformer`.\n",
    "- The grid is fully connected in the initial state.\n",
    "- The grid has no cycles in the initial state.\n",
    "- The timestamps are matching between the active load profile, reactive load profile, and EV charging profile.\n",
    "- The IDs in active load profile and reactive load profile are matching.\n",
    "- The IDs in active load profile and reactive load profile are valid IDs of `sym_load`.\n",
    "- The number of EV charging profile is at least the same as the number of `sym_load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import power_system_simulation as pss\n",
    "import pandas as pd\n",
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "\n",
    "dataset = json_deserialize_from_file(\"input_network_data_big.json\")\n",
    "reactive_power_data = pd.read_parquet(\"reactive_power_profile_big.parquet\")\n",
    "active_power_data = pd.read_parquet(\"active_power_profile_big.parquet\")\n",
    "ev_active_power_data = pd.read_parquet(\"ev_active_power_profile_big.parquet\")\n",
    "\n",
    "psm = pss.PowerSim(grid_data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 EV Penetration\n",
    "EV penetration is the amount of total vehicles that is electric. EV have a big impact on a power system since they use a lot of active power. Therefore it is important to simulate the effect of EV's in a power system.\n",
    "\n",
    "In this functionality, given an user input of the EV penetration level, it randomly adds EV charging profiles to houses according the following criteria: The number of EVs per LV feeder should be penetration_level * total_houses / number_of_feeders rounded down to the nearest integer.\n",
    "\n",
    "Afterwards a time-series power flow is ran, returning the 2 aggregation tables. It can be used by providing `grid_data`, `ev_active_power_profile`, `active_power_profile` and `reactive_power_profile`. Finally, you need to provide `num_houses`, `penetration_level` and `num_feeders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_houses = 150\n",
    "penetration_level = 20\n",
    "num_feeders = 7\n",
    "\n",
    "ev_penetration = psm.ev_penetration(num_houses, num_feeders, penetration_level, active_power_data, reactive_power_data, ev_active_power_data)\n",
    "\n",
    "ev_penetration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functionality works the following: \n",
    "- It calculates the EV's per feeder. \n",
    "- It puts all the data in the correct format. \n",
    "- It finds the LV feeders from the data.\n",
    "- It finds all the houses connected per LV feeder. \n",
    "- It keeps track of the assigned EV profiles to make sure every profile is assigned only once. \n",
    "- It randomly assigns an EV profile to a house until all the specified amount of houses have an EV. \n",
    "- It combines the active power profile with the EV's active power profile. \n",
    "- Finally, a time-series power flow is ran with this data. \n",
    "- The voltage table and the loading table are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Tap position\n",
    "In this functionality, the tap position is optimize of the transformer in the LV grid\n",
    "- The functionality returns the optimal tap position of the transformer by repeating time-series power flow calculation of the whole time periode for all possible tap positions.\n",
    "- After the power flow calculation the optimal tap position will return by:\n",
    "    - The minimal total energy loss of all the lines and the whole time period.\n",
    "    - The minimal deviation of p.u. node voltages with respect to 1 p.u.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put tap positon checks here to show it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 N-1 Calculations\n",
    "The N-1 functionality is used if the user would like to know an alternative grid topology when a given line is out of service, i.e. it is disabled. The user provides a to be disabled Line ID. The function will work as follows:\n",
    "- If the given Line ID is invalid, an error is raised\n",
    "- If the given Line ID is already disabled, an error is raised\n",
    "- The grid data is rewritten into a list, similar to assignment 1\n",
    "- The `alternative_edges` function from 1.4 is used\n",
    "- For every alternative edge, the power flow calculation from 2.3 is done and the loading table from 2.4 is constructed\n",
    "- From this loading table, the maximum loading, maximum loading ID and timestamp are collected and added to the N-1 table\n",
    "\n",
    "So in short, the function disconnects the given line and finds a list of line ID's that are currently disabled which can be connected to make the grid fully operational again. For each alternative line to be connected, the function returns a table giving the maximum loading for the new scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disabled_edge_id = 1984\n",
    "\n",
    "table = psm.n1_calculations(dataset, active_power_data, reactive_power_data, disabled_edge_id)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team collaboration\n",
    "\n",
    "In the beginning of the project deadlines were set for all three assigments. For every assigment we have divided the tasks and everyone mainly worked on it alone and when help was needed other teammates assisted. \n",
    "\n",
    "We had meetings twice a week which helped a lot to keep each other up-to-date. \n",
    "\n",
    "Everyone worked on their own branch and when something was finished it was check by other group members and approved/or improved and afterwards approved. \n",
    "\n",
    "\n",
    "# Lessons learnt\n",
    "\n",
    "Everyone did had limited experience with Python and Git, but this project we have learnt a lot about it. Now we feel a lot more comfortable with using Pylint, Isort and black. Commiting, making branches and push/pulling went very well in the team. Using the Github Desktop application also helped to understand everything. \n",
    "\n",
    "Sometimes it would have been benificial if we would have an 'officiall' meeting every week. Everyone was working well on their parts, but we were not always aware what the others were doing. \n",
    "\n",
    "After assignment 2 we were slightly behind schedule, but we were confident that we could finish it all so we did not really bother a lot when we were behind. This meant that we needed to do a little bit more on the final day, but we finished it all in the end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
