{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import power_system_simulation as pss\n",
    "import pandas as pd\n",
    "from power_grid_model.utils import json_deserialize_from_file\n",
    "import numpy as np\n",
    "import graph_processing as gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "             0\n",
      "0         node\n",
      "1         line\n",
      "2  transformer\n",
      "3       source\n",
      "4     sym_load\n"
     ]
    }
   ],
   "source": [
    "dataset = json_deserialize_from_file(\"input_network_data_assign3.json\")\n",
    "\n",
    "print(type(dataset))\n",
    "print(pd.DataFrame(dataset.keys()))\n",
    "\n",
    "# print(pd.DataFrame(dataset['line']))\n",
    "# print(pd.DataFrame(dataset['node']))\n",
    "# print(pd.DataFrame(dataset['transformer']))\n",
    "# print(pd.DataFrame(dataset['source']))\n",
    "# print(pd.DataFrame(dataset['sym_load']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ID                        12            13            14            15\n",
      "Timestamp                                                                  \n",
      "2025-01-01 00:00:00  -4125.774726  10138.692087   1128.989344   2737.227881\n",
      "2025-01-01 00:15:00  16401.177195 -18890.906272 -15686.701911 -15440.509838\n",
      "2025-01-01 00:30:00  14168.764135  10004.458792  12476.299329  18277.445982\n",
      "2025-01-01 00:45:00  12099.434484  -1516.888466   9174.032490 -15571.787249\n",
      "2025-01-01 01:00:00   5545.372267 -13336.327420  16457.603682    807.547193\n",
      "...                           ...           ...           ...           ...\n",
      "2025-01-10 22:45:00  20312.080701   7666.545676    793.539925  -3537.943985\n",
      "2025-01-10 23:00:00 -15947.820470   -916.845584 -17261.491025   3196.493251\n",
      "2025-01-10 23:15:00   8482.832761  15930.625066  -8487.686743  -4529.456669\n",
      "2025-01-10 23:30:00 -15291.785929  14796.648255  12155.264848  11322.252550\n",
      "2025-01-10 23:45:00 -18048.979231   2193.901032 -12565.357723 -15418.811806\n",
      "\n",
      "[960 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "reactive_power_data = pd.read_parquet('reactive_power_profile_assign3.parquet')\n",
    "\n",
    "print(reactive_power_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Load ID                        12            13            14            15\n",
      "Timestamp                                                                  \n",
      "2025-01-01 00:00:00  53845.936311  52868.809400  59437.379259  61193.999654\n",
      "2025-01-01 00:15:00  58623.012703  66992.056154  57797.477123  48956.385676\n",
      "2025-01-01 00:30:00  64800.016277  54713.600702  51293.354771  58092.153016\n",
      "2025-01-01 00:45:00  61525.469129  59903.401304  49747.760990  62055.246675\n",
      "2025-01-01 01:00:00  60289.133403  56883.894966  56301.650801  56226.510409\n",
      "...                           ...           ...           ...           ...\n",
      "2025-01-10 22:45:00  69484.715910  71348.849463  47979.322152  64352.546069\n",
      "2025-01-10 23:00:00  61503.570916  60836.586259  76135.394978  59164.472679\n",
      "2025-01-10 23:15:00  56045.155706  54275.886219  63557.959847  66834.711500\n",
      "2025-01-10 23:30:00  73370.995338  59556.779716  57056.774548  62640.438159\n",
      "2025-01-10 23:45:00  62018.984783  58840.504085  72134.414579  61673.554507\n",
      "\n",
      "[960 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "active_power_data = pd.read_parquet('active_power_profile_assign3.parquet')\n",
    "print(type(active_power_data))\n",
    "\n",
    "print(active_power_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who reads trek een bak\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# declare new PowerSimModel object\n",
    "test1 = pss.PowerSim(grid_data=dataset)\n",
    "\n",
    "# PowerSim saves the model as PowerSimModel\n",
    "# access to assignment 2 functions is now given as \n",
    "dataset = test1.PowerSimModel.batch_powerflow(active_power_profile=active_power_data, reactive_power_profile=reactive_power_data)\n",
    "aggregate_test = test1.PowerSimModel.aggregate_voltage_table(active_power_profile=active_power_data, reactive_power_profile=reactive_power_data)\n",
    "\n",
    "# PowerSim saves the model as PowerSimModel\n",
    "# access to assignment 3 functions is now\n",
    "print(test1.example_code())\n",
    "\n",
    "\n",
    "\n",
    "# (active_power_profile=active_power_data, reactive_power_profile=reactive_power_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-1 testing stuff\n",
    "- Firstly rewriting the input for assignment 1 function \"alternative edges\"\n",
    "- Then running the alternative edges function\n",
    "- For each alternative `line` to be connected, running the power flow calculation, with the original input type (?)\n",
    "- Make a table, similar to the loading table of assignment 2 with each row being an alternative scenario, containing:\n",
    "    - Alternative ID to be connected\n",
    "    - Maximum loading\n",
    "    - Line ID of the maximum\n",
    "    - Timestamp of the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alternative_Line_ID</th>\n",
       "      <th>Max_Loading</th>\n",
       "      <th>Max_Loading_ID</th>\n",
       "      <th>Max_Loading_Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-01-07 10:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alternative_Line_ID  Max_Loading  Max_Loading_ID Max_Loading_Timestamp\n",
       "0                   24     0.001659              21   2025-01-07 10:30:00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = json_deserialize_from_file(\"input_network_data_assign3.json\")\n",
    "\n",
    "test1 = pss.PowerSim(grid_data=dataset)\n",
    "\n",
    "line_disabled = 16\n",
    "\n",
    "# Now rewriting the output data to assignment 1 type of data:\n",
    "\n",
    "edge_vertex_id_pairs = list(zip(dataset[\"line\"][\"from_node\"], dataset[\"line\"][\"to_node\"])) + list(zip(dataset[\"transformer\"][\"from_node\"], dataset[\"transformer\"][\"to_node\"]))\n",
    "edge_enabled = []\n",
    "for i in dataset[\"line\"][\"id\"]:\n",
    "    index = np.where(dataset[\"line\"][\"id\"] == i)\n",
    "    if dataset[\"line\"][index][\"from_status\"] == 1 & dataset[\"line\"][index][\"to_status\"] == 1:\n",
    "        edge_enabled = edge_enabled + [True]\n",
    "    else:\n",
    "        edge_enabled = edge_enabled + [False]\n",
    "if dataset[\"transformer\"][0][\"from_status\"] == 1 & dataset[\"transformer\"][0][\"to_status\"] == 1:\n",
    "    edge_enabled = edge_enabled + [True]\n",
    "else:\n",
    "    edge_enabled = edge_enabled + [False]\n",
    "source_vertex_id = dataset[\"source\"][\"node\"][0]\n",
    "edge_ids = list(dataset[\"line\"][\"id\"]) + list(dataset[\"transformer\"][\"id\"])\n",
    "vertex_ids = dataset[\"node\"][\"id\"]\n",
    "\n",
    "# Find alternative edges\n",
    "\n",
    "test2 = gp.GraphProcessor(\n",
    "    vertex_ids=vertex_ids,\n",
    "    edge_ids=edge_ids,\n",
    "    edge_vertex_id_pairs=edge_vertex_id_pairs,\n",
    "    edge_enabled=edge_enabled,\n",
    "    source_vertex_id=source_vertex_id,\n",
    "    )\n",
    "\n",
    "alt_edges = test2.find_alternative_edges(line_disabled)\n",
    "\n",
    "# Run Powerflow table and aggregate table\n",
    "\n",
    "results = []\n",
    "\n",
    "line_data = dataset[\"line\"]\n",
    "\n",
    "\n",
    "for alt_line_id in alt_edges:\n",
    "    alt_line_index = None\n",
    "    for i in range(len(line_data[\"id\"])):\n",
    "        if line_data[\"id\"][i] == alt_line_id:\n",
    "            alt_line_index = i\n",
    "            break\n",
    "    if alt_line_index is not None:\n",
    "        line_data[\"to_status\"][alt_line_index] = 1  \n",
    "        output_data = test1.PowerSimModel.batch_powerflow(active_power_profile=active_power_data, reactive_power_profile=reactive_power_data)\n",
    "        loading_table = test1.PowerSimModel.aggregate_loading_table(active_power_profile=active_power_data, reactive_power_profile=reactive_power_data)\n",
    "\n",
    "        max_loading = loading_table[\"Max_Loading\"].max()\n",
    "        max_loading_id = loading_table[\"Max_Loading\"].idxmax()\n",
    "        max_loading_timestamp = loading_table.loc[max_loading_id, \"Max_Loading_Timestamp\"]\n",
    "\n",
    "        results.append({\n",
    "            \"Alternative_Line_ID\": alt_line_id,\n",
    "            \"Max_Loading\": max_loading,\n",
    "            \"Max_Loading_ID\": max_loading_id,\n",
    "            \"Max_Loading_Timestamp\": max_loading_timestamp\n",
    "        })\n",
    "results_df = pd.DataFrame(results)\n",
    "if results_df.empty:\n",
    "    results_df = pd.DataFrame(columns=[\"Alternative_Line_ID\", \"Max_Loading\", \"Max_Loading_ID\", \"Max_Loading_Timestamp\"])\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
